# Applied-AI-LLM-Engeering

AI Observability Utils — Latency Instrumentation Decorators

This project implements production-style Python instrumentation decorators used to monitor API and LLM execution performance.

The system measures function execution time, logs structured telemetry, and tracks latency statistics — simulating how real AI backends observe and debug model calls.
