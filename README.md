# Applied-AI-LLM-Engineering


Each folder contains:
- working code
- documentation
- runnable examples
- incremental production improvements

---

## ğŸ§  Engineering Principles

This repository follows real-world backend engineering practices:

- Clean architecture over notebooks
- Observability first
- Reusable utilities
- Incremental production readiness
- Measurable performance (latency, logging, metrics)

---

## ğŸš€ Learning Roadmap

### Phase 1 â€” Python & Backend Foundations
- Decorators & instrumentation
- Retry logic & error handling
- Async programming
- FastAPI services

### Phase 2 â€” Applied ML & NLP
- Embeddings & semantic search
- Vector databases
- Retrieval pipelines

### Phase 3 â€” Applied AI Systems
- RAG architectures
- Tool-calling agents
- Memory systems
- Multi-agent workflows

### Phase 4 â€” Production Engineering
- Deployment
- Monitoring
- System design
- Performance optimization

---

## ğŸ“¦ Tech Stack

- Python
- FastAPI
- Pydantic
- AsyncIO
- LangChain / LangGraph (later phases)
- Vector Databases (FAISS / Chroma)
- Structured Logging & Observability

---

## ğŸ”¬ Current Progress

| Week | Project | Status |
|------|--------|--------|
| 1 | Observability Decorators | ğŸš§ In Progress |
| 2 | Retry & Backoff | â³ Planned |
| 3 | Async Aggregator | â³ Planned |
| 4 | FastAPI AI Service | â³ Planned |

---

## ğŸ§ª How to Run (Example)

Each module includes its own instructions.

Example:

''' bash
cd 01-observability-decorators
python main.py '''


ğŸ‘¨â€ğŸ’» Author

Abdullah Jonaed
Software Engineer â†’ Applied AI Engineer
